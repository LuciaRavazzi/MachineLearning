{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(results):\n",
    "    lhs = [tuple(result[2][0][0])[0] for result in results]\n",
    "    rhs = [tuple(result[2][0][1])[0] for result in results]\n",
    "    support = [result[1] for result in results]\n",
    "    confidence = [result[2][0][2] for result in results]\n",
    "    lift = [result[2][0][3] for result in results]\n",
    "    return list(zip(lhs, rhs, support, confidence, lift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> ASSOCIATION RULE </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> APRIORI ALGORITHM </h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A well known myth in the data science is the association rule between the deepers and beer. Indeed, analizing thousands of transactions, it has discovered that association. It's interesting that some markets, after the knowledge of that association rule, has started to take deepers along with the beer in order to make easier the experience of buying. However, others decided to put far away the two products in order to verify if the association is true. Moreover, you are invitated to buy other during the path.\n",
    "\n",
    "There are association rules which are strong and weak. We want the former ones. Examples can take into account the liked movies or the transactions. \n",
    "The strongness of association rules $X \\rightarrow Y$ is measured with the **support** and **confidence**:\n",
    "\n",
    "$$\n",
    "support(X) = \\frac{\\# \\, units \\, with \\, X}{\\# \\, units}\n",
    "$$\n",
    "\n",
    "$$\n",
    "confidence(X \\rightarrow Y) = \\frac{\\# \\, units \\, with \\, X \\, \\cap \\, Y}{\\# \\, units \\, with \\,X}\n",
    "$$\n",
    "\n",
    "**Lift** give the information about how much the probability of a fact'll be modified if apropri knoledge is took into account.\n",
    "$$\n",
    "lift(X \\rightarrow Y) = \\frac{confidence(X \\rightarrow Y)}{support(X)}\n",
    "$$\n",
    "For instance, I have the probability on the population that define how many people watch ex-machina. However, the same propability, but computed with the information that the user has watched Interstellar, change. So, the lift say to us the how many the probability change if apriori knowledge is introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Apriori algorithm** is made of the following steps:\n",
    "- Set a minimum support and confidence.\n",
    "- Take all the subsets in transactions having higher support and minimum support. They can be a huge amount.\n",
    "- Take all the rules of these subsets having higher confidence than the minimum threshold.\n",
    "- Sort the rule by deceasing lift.\n",
    "\n",
    "Reccomended system, the ones which suggest new purchases, like Amazon or Netflix use a sophisticated algorithm like that. They rely on what you've bought and through association rules, they suggest you several products. Moreover, the deal of buy one and you'll have another free relies on these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LHS</th>\n",
       "      <th>RHS</th>\n",
       "      <th>SUPPORT</th>\n",
       "      <th>CONFIDENCE</th>\n",
       "      <th>LIFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fromage blanc</td>\n",
       "      <td>honey</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>5.164271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>light cream</td>\n",
       "      <td>chicken</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>4.843951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pasta</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>4.700812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pasta</td>\n",
       "      <td>shrimp</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>4.506672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whole wheat pasta</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>4.122410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tomato sauce</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>3.840659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushroom cream sauce</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.300699</td>\n",
       "      <td>3.790833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>herb &amp; pepper</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.015998</td>\n",
       "      <td>0.323450</td>\n",
       "      <td>3.291994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>light cream</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>3.114710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LHS          RHS   SUPPORT  CONFIDENCE      LIFT\n",
       "3         fromage blanc        honey  0.003333    0.245098  5.164271\n",
       "0           light cream      chicken  0.004533    0.290598  4.843951\n",
       "2                 pasta     escalope  0.005866    0.372881  4.700812\n",
       "8                 pasta       shrimp  0.005066    0.322034  4.506672\n",
       "7     whole wheat pasta    olive oil  0.007999    0.271493  4.122410\n",
       "5          tomato sauce  ground beef  0.005333    0.377358  3.840659\n",
       "1  mushroom cream sauce     escalope  0.005733    0.300699  3.790833\n",
       "4         herb & pepper  ground beef  0.015998    0.323450  3.291994\n",
       "6           light cream    olive oil  0.003200    0.205128  3.114710"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Dataset/Market_Basket_Optimisation.csv', header = None)\n",
    "\n",
    "# reshape to the following steps.\n",
    "transactions = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    transactions.append([str(data.values[i,j]) for j in range(0, data.shape[1])])\n",
    "    \n",
    "# train the apriori model.\n",
    "rules = apriori(transactions = transactions, # dataset.\n",
    "               min_support =  0.003, # 3 times the product is purchased in a day * 7 days/data.shape[0] (common sense)\n",
    "               min_confidence = 0.2, # rule of thumb: 0.8\n",
    "               min_lift = 3, # measure the quality of a rule; based on experience.\n",
    "               min_length = 2, # only one X and \n",
    "               max_length= 2) # one Y\n",
    "\n",
    "# visualize the result.\n",
    "results = list(rules); \n",
    "\n",
    "DATA = pd.DataFrame(inspect(results), columns = ['LHS', 'RHS', 'SUPPORT', 'CONFIDENCE', 'LIFT']); DATA\n",
    "DATA.nlargest(n = 10, # best rules.\n",
    "             columns = 'LIFT')\n",
    "\n",
    "# we want to find the association rules with the highest LIFT since wen know that\n",
    "# if someone buy X, it'll probably buy also Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> ECLAT ALGORITHM </h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support factor remains one important parameter: indeed, confidence and lift aren't used.\n",
    "It's made of the following steps:\n",
    "- Set a minimum support.\n",
    "- Take all the subsets in transactions having higher support than minimum support.\n",
    "- Sort these subsets by decresing support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LHS</th>\n",
       "      <th>RHS</th>\n",
       "      <th>SUPPORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>herb &amp; pepper</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.015998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whole wheat pasta</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>0.007999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pasta</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mushroom cream sauce</td>\n",
       "      <td>escalope</td>\n",
       "      <td>0.005733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tomato sauce</td>\n",
       "      <td>ground beef</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pasta</td>\n",
       "      <td>shrimp</td>\n",
       "      <td>0.005066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>light cream</td>\n",
       "      <td>chicken</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fromage blanc</td>\n",
       "      <td>honey</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>light cream</td>\n",
       "      <td>olive oil</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LHS          RHS   SUPPORT\n",
       "4         herb & pepper  ground beef  0.015998\n",
       "7     whole wheat pasta    olive oil  0.007999\n",
       "2                 pasta     escalope  0.005866\n",
       "1  mushroom cream sauce     escalope  0.005733\n",
       "5          tomato sauce  ground beef  0.005333\n",
       "8                 pasta       shrimp  0.005066\n",
       "0           light cream      chicken  0.004533\n",
       "3         fromage blanc        honey  0.003333\n",
       "6           light cream    olive oil  0.003200"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THE TRUE ALGORITHM DROP THE PARAMETERS FOR THE CONFIDENCE AND THE \n",
    "# LIFT BUT WE TAKE THEM IN ORDER TO HAVE A STRONGER RULES.\n",
    "# HOWEVER, FINALLY ONLY RULES WITH THE HIGHEST SUPPORT WILL RETAIN.\n",
    "\n",
    "DATA.nlargest(n = 10, # best rules.\n",
    "             columns = 'SUPPORT')[['LHS', 'RHS', 'SUPPORT']]\n",
    "\n",
    "# we want to find the association rules with the highest LIFT since wen know that\n",
    "# if someone buy X, it'll probably buy also Y."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
