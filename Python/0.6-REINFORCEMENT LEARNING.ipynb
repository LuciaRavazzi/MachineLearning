{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> REINFORCEMENT LEARNING </h1></center>\n",
    "\n",
    "We want to define the path which maximize the total reward. Basic reinforcement is modeled as a Markov decision process (MDP):\n",
    "- a set of environment and agent states, $S$;\n",
    "- a set of actions, $A$, of the agent;\n",
    "- $P_{a}(s,s')=\\Pr(s_{t+1}=s'\\mid s_{t}=s,a_{t}=a)$ is the probability of transition (at time ${\\displaystyle t}$) from state ${\\displaystyle s}$ to state ${\\displaystyle s'}$ under action $a$. \n",
    "- ${\\displaystyle R_{a}(s,s')}$ is the immediate reward after transition from $s$ to $s'$ with action $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> UPPER-CONFIDENCE BOUND </h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a branch of AI rather than ML. One example is the algorithm which define the movements of a robot dog. There are two main approaches to make the dog walking: give a set of instructions that it must make or train the dog with them plus the bonus (1) and punishment (0) which it'll gain. It isn't necessary to program the robot but the reinforcement learnind do the job. \n",
    "\n",
    "We define the **Multi-Armed bandit problem**. \n",
    "However, there are several examples of RL. \n",
    "One armed machine is a slot machine. The aim is to understand the best machine in order to maximize the profit. Each of them is characterized by an unknown distribution of winning. Our goal is to find the best reward. In our case, the best is the right one because the mode is on the right (max reward) and the probability is the highest one. \n",
    "So, the problem aims to find the best machines which is characterized by the best distribution in order to maximize my profits. \n",
    "The technique must be relied on the right mix of _exploitation_ and _exploration_. If the latter approach overcome on the former, the searching technique for finding the best machines will be poor. Once the best machine is found with the exploration approach, the exploitation approach will be applied. _Regret_ is the scenario in which we aren't using the optimal machine and it's quantified with the difference between the best outcome and the one obtained. The longer we explore the wrong machine, the regret increases. \n",
    "\n",
    "Another example is the search of the right image to advertise a drink in order to maximize the outcome. We don't know the distributionn: we can know it only in the case in which many users click them. The A/B test cannot be performed due to time limitation and it makean exploration: so, the fair mix between exploitation and exploration must be searched. \n",
    "\n",
    "The **Upper Confidence Bound Algorithm** for our problem follows the following steps:\n",
    "- Assume to have $d$ types of ads. \n",
    "- Each time a user connects to a web page, one ads over $d$ is chosen.\n",
    "- At each round $n$, ad $i$ gives a reward $r_i(n) \\in {0,1}$: $r_i(n) = 1$ if the user clicked on the $i$ ad, $0$ otherwise.\n",
    "- Our goal is to maximize the total reward we get over many rounds.\n",
    "So,\n",
    "- At each round $n$, we consider $N_i(n)$, namely the number of times the ad $i$ *was selected* (IT MUST BE SELECTED, OTHERWISE IT REMAINS THE SAME FOR THE HIGHEST UCB) up to round $n$, and $R_i(n)$, thus the number of rewards of $i$ ad up to $n$ rounds (IT MUST BE SELECTED FOR THE HIGHEST UCB).\n",
    "- Compute $r_i(n) = \\frac{R_i(n)}{N_i(n)}$, thus the mean number of rewards for $i$ ad, and the associated confidence interval since we are managing a sample. Select the $i$ ad with the **highest upper confidence level**.\n",
    "- The exploration stops when we select the sd with th highest upper level. The, the exploitation phase can start.\n",
    "\n",
    "These steps is built for a discrete distribution (in the advertise we are seeking for the proportion). While for the slot machines, we are estimating the mean of the distribution. So, the reward is how much I won and the punishment is how much I lost. $N$ remain the same in order to have a mean. So, $r_i(n)$ is the _mean_ of the money that I won. In this case, starting from a sample, I try to estimate the mean of what I won. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAUdUlEQVR4nO3df4xl5X3f8ffHrB1jYgcw9ojsoixOVrZJthg6AlIkawoRvxwFKhkJRO0FUe0/xCXtSuna/YMWxxKRQhw7ja1uzTpLaocgbAtkkMkKe1TlDzBgCBjWLhtMYQMxTheI127sTvrtH/cZM8PO7tz5sXOX+7xf0uie873Pc+9zHt353HPPnHsmVYUkqQ9vGPUAJElrx9CXpI4Y+pLUEUNfkjpi6EtSR9aNegCHc9JJJ9XGjRuX3f9HP/oRxx133OoN6HXMuZjP+XiVczHfOMzHww8//PdV9Y6F7juqQ3/jxo089NBDy+4/PT3N1NTU6g3odcy5mM/5eJVzMd84zEeS/3Wo+zy8I0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTmqv5ErLWbj9ruX1W/b5hmuXmbfWc/c9IEV9ZdGwT19SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGhQj/J8UnuSPKdJHuS/HqSE5PsTvJUuz2htU2STyfZm+SxJGfOeZwtrf1TSbYcqY2SJC1s2D39TwFfq6r3AKcDe4DtwH1VtQm4r60DXAxsaj9bgc8CJDkRuAE4GzgLuGH2jUKStDYWDf0kbwPeD9wCUFU/raqXgUuBXa3ZLuCytnwpcGsN3A8cn+Rk4EJgd1Xtr6qXgN3ARau6NZKkwxrmG7nvAn4AfD7J6cDDwPXARFW9AFBVLyR5Z2u/HnhuTv99rXao+jxJtjL4hMDExATT09NL2Z55Dhw4sKL+42Rc52Lb5pll9Zs4dvl9Z43LfI7ra2O5xn0+hgn9dcCZwEeq6oEkn+LVQzkLyQK1Okx9fqFqB7ADYHJyslbyD4rH4R8cr5ZxnYvlXkph2+YZbn58ZVcheeaqqRX1P1qM62tjucZ9PoY5pr8P2FdVD7T1Oxi8CXy/Hbah3b44p/0pc/pvAJ4/TF2StEYWDf2q+jvguSTvbqXzgSeBu4DZM3C2AHe25buAD7ezeM4BXmmHge4FLkhyQvsD7gWtJklaI8N+vv0I8IUkbwKeBq5h8IZxe5JrgWeBy1vbe4BLgL3Aj1tbqmp/ko8DD7Z2N1bV/lXZCknSUIYK/ap6FJhc4K7zF2hbwHWHeJydwM6lDFCStHr8Rq4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjQ4V+kmeSPJ7k0SQPtdqJSXYneardntDqSfLpJHuTPJbkzDmPs6W1fyrJliOzSZKkQ1nKnv6/rKr3VdVkW98O3FdVm4D72jrAxcCm9rMV+CwM3iSAG4CzgbOAG2bfKCRJa2Mlh3cuBXa15V3AZXPqt9bA/cDxSU4GLgR2V9X+qnoJ2A1ctILnlyQt0boh2xXwl0kK+K9VtQOYqKoXAKrqhSTvbG3XA8/N6buv1Q5VnyfJVgafEJiYmGB6enr4rXmNAwcOrKj/OBnXudi2eWZZ/SaOXX7fWeMyn+P62liucZ+PYUP/3Kp6vgX77iTfOUzbLFCrw9TnFwZvKDsAJicna2pqasghHmx6epqV9B8n4zoXV2+/e1n9tm2e4ebHh335L+yZq6ZW1P9oMa6vjeUa9/kY6vBOVT3fbl8EvsLgmPz322Eb2u2Lrfk+4JQ53TcAzx+mLklaI4uGfpLjkrx1dhm4APg2cBcwewbOFuDOtnwX8OF2Fs85wCvtMNC9wAVJTmh/wL2g1SRJa2SYz7cTwFeSzLb/YlV9LcmDwO1JrgWeBS5v7e8BLgH2Aj8GrgGoqv1JPg482NrdWFX7V21LJEmLWjT0q+pp4PQF6v8bOH+BegHXHeKxdgI7lz5MSdJq8Bu5ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjgwd+kmOSfJIkq+29VOTPJDkqSR/keRNrf5zbX1vu3/jnMf4aKt/N8mFq70xkqTDW8qe/vXAnjnrvw98sqo2AS8B17b6tcBLVfUrwCdbO5KcBlwB/CpwEfCZJMesbPiSpKUYKvSTbAA+AHyurQc4D7ijNdkFXNaWL23rtPvPb+0vBW6rqp9U1feAvcBZq7ERkqThrBuy3R8Bvwu8ta2/HXi5qmba+j5gfVteDzwHUFUzSV5p7dcD9895zLl9fibJVmArwMTEBNPT08Nuy0EOHDiwov7jZFznYtvmmcUbLWDi2OX3nTUu8zmur43lGvf5WDT0k/wm8GJVPZxkara8QNNa5L7D9Xm1ULUD2AEwOTlZU1NTr20ytOnpaVbSf5yM61xcvf3uZfXbtnmGmx8fdp9nYc9cNbWi/keLcX1tLNe4z8cwr/pzgd9KcgnwZuBtDPb8j0+yru3tbwCeb+33AacA+5KsA34B2D+nPmtuH0nSGlj0mH5VfbSqNlTVRgZ/iP16VV0FfAP4YGu2BbizLd/V1mn3f72qqtWvaGf3nApsAr65alsiSVrUSj7f/gfgtiS/BzwC3NLqtwB/lmQvgz38KwCq6okktwNPAjPAdVX1Tyt4fknSEi0p9KtqGphuy0+zwNk3VfWPwOWH6P8J4BNLHaQkaXX4jVxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrJo6Cd5c5JvJvnrJE8k+c+tfmqSB5I8leQvkryp1X+ure9t92+c81gfbfXvJrnwSG2UJGlhw+zp/wQ4r6pOB94HXJTkHOD3gU9W1SbgJeDa1v5a4KWq+hXgk60dSU4DrgB+FbgI+EySY1ZzYyRJh7do6NfAgbb6xvZTwHnAHa2+C7isLV/a1mn3n58krX5bVf2kqr4H7AXOWpWtkCQNZahj+kmOSfIo8CKwG/gb4OWqmmlN9gHr2/J64DmAdv8rwNvn1hfoI0laA+uGaVRV/wS8L8nxwFeA9y7UrN3mEPcdqj5Pkq3AVoCJiQmmp6eHGeKCDhw4sKL+42Rc52Lb5pnFGy1g4tjl9501LvM5rq+N5Rr3+Rgq9GdV1ctJpoFzgOOTrGt78xuA51uzfcApwL4k64BfAPbPqc+a22fuc+wAdgBMTk7W1NTUUoY4z/T0NCvpP07GdS6u3n73svpt2zzDzY8v6eV/kGeumlpR/6PFuL42lmvc52OYs3fe0fbwSXIs8BvAHuAbwAdbsy3AnW35rrZOu//rVVWtfkU7u+dUYBPwzdXaEEnS4obZ1TkZ2NXOtHkDcHtVfTXJk8BtSX4PeAS4pbW/BfizJHsZ7OFfAVBVTyS5HXgSmAGua4eNJElrZNHQr6rHgDMWqD/NAmffVNU/Apcf4rE+AXxi6cOUJK0Gv5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyKKhn+SUJN9IsifJE0mub/UTk+xO8lS7PaHVk+TTSfYmeSzJmXMea0tr/1SSLUdusyRJCxlmT38G2FZV7wXOAa5LchqwHbivqjYB97V1gIuBTe1nK/BZGLxJADcAZwNnATfMvlFIktbGoqFfVS9U1bfa8g+BPcB64FJgV2u2C7isLV8K3FoD9wPHJzkZuBDYXVX7q+olYDdw0apujSTpsNYtpXGSjcAZwAPARFW9AIM3hiTvbM3WA8/N6bav1Q5Vf+1zbGXwCYGJiQmmp6eXMsR5Dhw4sKL+42Rc52Lb5pll9Zs4dvl9Z43LfI7ra2O5xn0+hg79JD8PfAn4nar6hySHbLpArQ5Tn1+o2gHsAJicnKypqalhh3iQ6elpVtJ/nIzrXFy9/e5l9du2eYabH1/SPs9BnrlqakX9jxbj+tpYrnGfj6HO3knyRgaB/4Wq+nIrf78dtqHdvtjq+4BT5nTfADx/mLokaY0Mc/ZOgFuAPVX1h3PuuguYPQNnC3DnnPqH21k85wCvtMNA9wIXJDmh/QH3glaTJK2RYT7fngt8CHg8yaOt9jHgJuD2JNcCzwKXt/vuAS4B9gI/Bq4BqKr9ST4OPNja3VhV+1dlKyRJQ1k09Kvqr1j4eDzA+Qu0L+C6QzzWTmDnUgYoSVo9fiNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSPrRj0ASa8fG7ffPZLnfeamD4zkeceRe/qS1BFDX5I6smjoJ9mZ5MUk355TOzHJ7iRPtdsTWj1JPp1kb5LHkpw5p8+W1v6pJFuOzOZIkg5nmD39PwUuek1tO3BfVW0C7mvrABcDm9rPVuCzMHiTAG4AzgbOAm6YfaOQJK2dRUO/qv4HsP815UuBXW15F3DZnPqtNXA/cHySk4ELgd1Vtb+qXgJ2c/AbiSTpCFvu2TsTVfUCQFW9kOSdrb4eeG5Ou32tdqj6QZJsZfApgYmJCaanp5c5RDhw4MCK+o+TcZ2LbZtnltVv4tjl9501LvO5lNfGSudsudZyrsf1d2XWap+ymQVqdZj6wcWqHcAOgMnJyZqamlr2YKanp1lJ/3EyrnNx9TJPIdy2eYabH1/Zy/+Zq6ZW1P9osZTXxnLne6XWcq7H9Xdl1nLP3vl+O2xDu32x1fcBp8xptwF4/jB1SdIaWm7o3wXMnoGzBbhzTv3D7Syec4BX2mGge4ELkpzQ/oB7QatJktbQop9vk/w5MAWclGQfg7NwbgJuT3It8CxweWt+D3AJsBf4MXANQFXtT/Jx4MHW7saqeu0fhyVJR9iioV9VVx7irvMXaFvAdYd4nJ3AziWNTpK0qvxGriR1xNCXpI4Y+pLUEUNfkjoy1tfTf/xvXxnJl0m89reko5V7+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGx/kbuqGwc1b+U85vAkhbhnr4kdcQ9fa2KUX26kbQ0hr70OrPab7DbNs+M5MKEGg1DX9JRby0/Sc59ExzHv5N5TF+SOmLoS1JHPLwzRg73EdjjttLSjfIEhSN1aMnQl5bJM5b0euThHUnqyJqHfpKLknw3yd4k29f6+SWpZ2sa+kmOAf4EuBg4DbgyyWlrOQZJ6tla7+mfBeytqqer6qfAbcClazwGSepWqmrtniz5IHBRVf2btv4h4Oyq+u05bbYCW9vqu4HvruApTwL+fgX9x4lzMZ/z8SrnYr5xmI9fqqp3LHTHWp+9kwVq8951qmoHsGNVnix5qKomV+OxXu+ci/mcj1c5F/ON+3ys9eGdfcApc9Y3AM+v8RgkqVtrHfoPApuSnJrkTcAVwF1rPAZJ6taaHt6pqpkkvw3cCxwD7KyqJ47gU67KYaIx4VzM53y8yrmYb6znY03/kCtJGi2/kStJHTH0JakjYxn6XurhVUlOSfKNJHuSPJHk+lGPadSSHJPkkSRfHfVYRi3J8UnuSPKd9hr59VGPaZSS/Lv2e/LtJH+e5M2jHtNqG7vQ91IPB5kBtlXVe4FzgOs6nw+A64E9ox7EUeJTwNeq6j3A6XQ8L0nWA/8WmKyqX2NwsskVox3V6hu70MdLPcxTVS9U1bfa8g8Z/FKvH+2oRifJBuADwOdGPZZRS/I24P3ALQBV9dOqenm0oxq5dcCxSdYBb2EMv0c0jqG/Hnhuzvo+Og65uZJsBM4AHhjtSEbqj4DfBf7fqAdyFHgX8APg8+1w1+eSHDfqQY1KVf0t8AfAs8ALwCtV9ZejHdXqG8fQX/RSDz1K8vPAl4Dfqap/GPV4RiHJbwIvVtXDox7LUWIdcCbw2ao6A/gR0O3fwJKcwOCowKnALwLHJfnXox3V6hvH0PdSD6+R5I0MAv8LVfXlUY9nhM4FfivJMwwO+52X5L+PdkgjtQ/YV1Wzn/zuYPAm0KvfAL5XVT+oqv8LfBn4FyMe06obx9D3Ug9zJAmDY7Z7quoPRz2eUaqqj1bVhqrayOB18fWqGrs9uWFV1d8BzyV5dyudDzw5wiGN2rPAOUne0n5vzmcM/7A9dv8jdwSXejjanQt8CHg8yaOt9rGqumeEY9LR4yPAF9oO0tPANSMez8hU1QNJ7gC+xeCst0cYw0syeBkGSerIOB7ekSQdgqEvSR0x9CWpI4a+JHXE0Jekjhj60gKS/KskleQ9bX1jkv/TLlewJ8k3k2yZ034iyVeT/HWSJ5N4SqyOSmN3nr60Sq4E/orBl7j+U6v9TbtcAUneBXw5yRuq6vPAjcDuqvpUu/+frf2QpcW5py+9RrtO0bnAtRzi0rpV9TTw7xlcihfgZAaXNZi9/7EjPExpWQx96WCXMbjG/P8E9ic51PVovgW8py3/CXBL+4c1/zHJL67FQKWlMvSlg13J4IJstNsrD9HuZ1d0rap7GVyq+L8xeCN4JMk7juQgpeXwmL40R5K3A+cBv5akGFy/qYDPLND8DOZckKuq9gNfBL7Y/hXj+xlc3VQ6arinL833QeDWqvqlqtpYVacA32Nwie6faf+Q5g+AP27r5yV5S1t+K/DLDK7aKB1V3NOX5rsSuOk1tS8BHwN+OckjwJuBHwJ/3M7cAfjnwH9JMsNgZ+pzVfXgGo1ZGppX2ZSkjnh4R5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjvx/w0EbPMP9POcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tha aim is to understand the ad with the best click-through rate.\n",
    "\n",
    "# a record is characterized by the totality of ads which the user select (it's a simulation).\n",
    "# Actually, I haven't these information because the user give me one information at a time.\n",
    "# This is a simulation, indeed I know all of the rewards!\n",
    "# In the multi-armed problem, I define the reward each time the i-th is selected.\n",
    "dataset = pd.read_csv('Dataset/Ads_CTR_Optimisation.csv')\n",
    "\n",
    "import math\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "numbers_of_selections = [0] * d\n",
    "sums_of_rewards = [0] * d\n",
    "total_reward = 0\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_upper_bound = 0\n",
    "    for i in range(0, d):\n",
    "        if (numbers_of_selections[i] > 0):\n",
    "            average_reward = sums_of_rewards[i] / numbers_of_selections[i]\n",
    "            delta_i = math.sqrt(3/2 * math.log(n + 1) / numbers_of_selections[i])\n",
    "            upper_bound = average_reward + delta_i\n",
    "        else:\n",
    "            upper_bound = 1e400\n",
    "        if (upper_bound > max_upper_bound):\n",
    "            max_upper_bound = upper_bound\n",
    "            ad = i\n",
    "    ads_selected.append(ad)\n",
    "    numbers_of_selections[ad] = numbers_of_selections[ad] + 1\n",
    "    reward = dataset.values[n, ad]\n",
    "    sums_of_rewards[ad] = sums_of_rewards[ad] + reward\n",
    "    total_reward = total_reward + reward\n",
    "    \n",
    "plt.hist(ads_selected)\n",
    "plt.xlabel('ADS')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# the five ads is the most click-beating and so the best one.\n",
    "# If N=500, there isn't a winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> THOMPSON SAMPLING </h3></center>\n",
    "\n",
    "It's made of the following steps:\n",
    "- At each round $n$, we consider two numbers for each $i$: $N_i^1(n)$, namely the number of times the ad $i$ got reward $1$ up to round $n$, and $N_i^0(n)$, hence the number of times the ad $i$ got reward $0$ up to round $n$.\n",
    "- For each ad $i$, we take a random draw from the distribution below: $\\theta_i(n) = \\beta(N_i^1(n)+1, N_i^0(n)+1)$\n",
    "- We select the ad that has the highest $\\theta_i(n)$. Then the values of $N_i^1(n)$ and $N_i^0(n)$ for that $i$ will be up to date.\n",
    "\n",
    "\n",
    "We start to pull each machine several times. Given several rewards of those machines, the thompson algorithm tries to build the distributions of where we think the actual expected value might lie. So, we aren't building the distribution of the machine but the one of the estimator of the sample mean on the basis of the provided values. We are seeking of the distribution of the _estimator for the mean_. Then, we pull a value from each of the distribution in order to generate our own virtual bandit configuration. Select the one with the best reward and then pull the lever of that machine. Then, the distribution of the mean must be adjusted on the basis of the new provided value. Other rounds are based on the definition of new virtual configuration, selecting the one with the best reward and finally, lever this one. If a machine is selected for a huge number of times, LGN will guarantee the convergence to the true mean of the distribution. It's a probabilistic algorithm, unlike the UCB that is a deterministic algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAR6ElEQVR4nO3de4yddZ3H8fdH6g28AKITbBuL2ogIa8AJoiRmQl1uGssmkkBYLYZNkw0quiRudf9g4yXBxHhdNekCLrgqskgCEVds0MnGZEFurgqVpQssjFTRFNB6r/vdP86vzpk6Q3suM2c8834lk3me3/P7PfOd35zpZ57LeZqqQpK0sj1l1AVIkkbPMJAkGQaSJMNAkoRhIEkCVo26gH4dccQRtW7dur7G/vKXv+SQQw4ZbkF/ppyLuZyPuZyPWeMwF3fcccfPqur58237sw2DdevWcfvtt/c1dnp6mqmpqeEW9GfKuZjL+ZjL+Zg1DnOR5H8X2rbf00RJrkjyaJIfdLUdnmRbkvva58Nae5J8MsmOJN9LckLXmE2t/31JNnW1vyrJ99uYTyZJ/9+qJKkfB3LN4F+A0/dp2wLcXFXrgZvbOsAZwPr2sRn4LHTCA7gEeDVwInDJ3gBpfTZ3jdv3a0mSFtl+w6Cq/gPYtU/zRuDKtnwlcFZX+1XVcQtwaJIjgdOAbVW1q6oeA7YBp7dtz6mq/6zOW6Gv6tqXJGmJ9Hs30URV7QRon1/Q2lcDD3f1m2ltT9Y+M0+7JGkJDfsC8nzn+6uP9vl3nmymc0qJiYkJpqen+ygRdu/e3ffYceNczOV8zOV8zBr3ueg3DH6S5Miq2tlO9Tza2meAtV391gCPtPapfdqnW/uaefrPq6q2AlsBJicnq98r++NwV8CwOBdzOR9zOR+zxn0u+j1NdAOw946gTcD1Xe1vbXcVnQQ80U4j3QScmuSwduH4VOCmtu0XSU5qdxG9tWtfkqQlst8jgyRfovNX/RFJZujcFXQpcE2SC4CHgLNb968BZwI7gF8BbwOoql1JPgDc1vq9v6r2XpT+Wzp3LD0T+Pf2IUlaQvsNg6o6d4FNG+bpW8CFC+znCuCKedpvB47dXx2SpMXzZ/sOZGm5WrflxpF83QcvfcNIvq7Ggw+qkyQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSA4ZBkncnuTvJD5J8KckzkhyV5NYk9yX5cpKntb5Pb+s72vZ1Xft5b2u/N8lpg31LkqRe9R0GSVYD7wQmq+pY4CDgHODDwMeqaj3wGHBBG3IB8FhVvRT4WOtHkmPauFcApwOfSXJQv3VJkno36GmiVcAzk6wCDgZ2AqcA17btVwJnteWNbZ22fUOStParq+q3VfUAsAM4ccC6JEk9WNXvwKr6UZKPAA8Bvwa+AdwBPF5Ve1q3GWB1W14NPNzG7knyBPC81n5L1667x8yRZDOwGWBiYoLp6em+at+9e3ffY8eNczHXMObj4uP27L/TIliMn6Ovj1njPhd9h0GSw+j8VX8U8Djwb8AZ83StvUMW2LZQ+582Vm0FtgJMTk7W1NRUb0U309PT9Dt23DgXcw1jPs7fcuNwiunRg+dNDX2fvj5mjftcDHKa6PXAA1X106r6PXAd8Frg0HbaCGAN8EhbngHWArTtzwV2dbfPM0aStAQGCYOHgJOSHNzO/W8A7gG+Bby59dkEXN+Wb2jrtO3frKpq7ee0u42OAtYD3xmgLklSjwa5ZnBrkmuBO4E9wF10TuHcCFyd5IOt7fI25HLg80l20DkiOKft5+4k19AJkj3AhVX1h37rkiT1ru8wAKiqS4BL9mm+n3nuBqqq3wBnL7CfDwEfGqQWSVL/fAeyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIYMAySHJrk2iQ/TLI9yWuSHJ5kW5L72ufDWt8k+WSSHUm+l+SErv1sav3vS7Jp0G9KktSbQY8MPgF8vaqOBl4JbAe2ADdX1Xrg5rYOcAawvn1sBj4LkORw4BLg1cCJwCV7A0SStDT6DoMkzwFeB1wOUFW/q6rHgY3Ala3blcBZbXkjcFV13AIcmuRI4DRgW1XtqqrHgG3A6f3WJUnq3SBHBi8Gfgp8LsldSS5LcggwUVU7AdrnF7T+q4GHu8bPtLaF2iVJS2TVgGNPAN5RVbcm+QSzp4Tmk3na6kna/3QHyWY6p5iYmJhgenq6p4L32r17d99jx41zMdcw5uPi4/YMp5geLcbP0dfHrHGfi0HCYAaYqapb2/q1dMLgJ0mOrKqd7TTQo13913aNXwM80tqn9mmfnu8LVtVWYCvA5ORkTU1Nzddtv6anp+l37LhxLuYaxnycv+XG4RTTowfPmxr6Pn19zBr3uej7NFFV/Rh4OMnLWtMG4B7gBmDvHUGbgOvb8g3AW9tdRScBT7TTSDcBpyY5rF04PrW1SZKWyCBHBgDvAL6Q5GnA/cDb6ATMNUkuAB4Czm59vwacCewAftX6UlW7knwAuK31e39V7RqwLklSDwYKg6r6LjA5z6YN8/Qt4MIF9nMFcMUgtUiS+uc7kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSWIIYZDkoCR3JflqWz8qya1J7kvy5SRPa+1Pb+s72vZ1Xft4b2u/N8lpg9YkSerNMI4MLgK2d61/GPhYVa0HHgMuaO0XAI9V1UuBj7V+JDkGOAd4BXA68JkkBw2hLknSARooDJKsAd4AXNbWA5wCXNu6XAmc1ZY3tnXa9g2t/0bg6qr6bVU9AOwAThykLklSb1YNOP7jwHuAZ7f15wGPV9Wetj4DrG7Lq4GHAapqT5InWv/VwC1d++weM0eSzcBmgImJCaanp/sqevfu3X2PHTfOxVzDmI+Lj9uz/06LYDF+jr4+Zo37XPQdBkneCDxaVXckmdrbPE/X2s+2Jxszt7FqK7AVYHJysqampubrtl/T09P0O3bcOBdzDWM+zt9y43CK6dGD500NfZ++PmaN+1wMcmRwMvCmJGcCzwCeQ+dI4dAkq9rRwRrgkdZ/BlgLzCRZBTwX2NXVvlf3GEnSEuj7mkFVvbeq1lTVOjoXgL9ZVecB3wLe3LptAq5vyze0ddr2b1ZVtfZz2t1GRwHrge/0W5ckqXeDXjOYz98DVyf5IHAXcHlrvxz4fJIddI4IzgGoqruTXAPcA+wBLqyqPyxCXZKkBQwlDKpqGphuy/czz91AVfUb4OwFxn8I+NAwapEk9c53IEuSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiQHCIMnaJN9Ksj3J3Ukuau2HJ9mW5L72+bDWniSfTLIjyfeSnNC1r02t/31JNg3+bUmSejHIkcEe4OKqejlwEnBhkmOALcDNVbUeuLmtA5wBrG8fm4HPQic8gEuAVwMnApfsDRBJ0tLoOwyqamdV3dmWfwFsB1YDG4ErW7crgbPa8kbgquq4BTg0yZHAacC2qtpVVY8B24DT+61LktS7VcPYSZJ1wPHArcBEVe2ETmAkeUHrthp4uGvYTGtbqH2+r7OZzlEFExMTTE9P91Xv7t27+x47bpyLuYYxHxcft2c4xfRoMX6Ovj5mjftcDBwGSZ4FfAV4V1X9PMmCXedpqydp/9PGqq3AVoDJycmamprquV7o/NL0O3bcOBdzDWM+zt9y43CK6dGD500NfZ++PmaN+1wMdDdRkqfSCYIvVNV1rfkn7fQP7fOjrX0GWNs1fA3wyJO0S5KWyCB3EwW4HNheVR/t2nQDsPeOoE3A9V3tb213FZ0EPNFOJ90EnJrksHbh+NTWJklaIoOcJjoZeAvw/STfbW3vAy4FrklyAfAQcHbb9jXgTGAH8CvgbQBVtSvJB4DbWr/3V9WuAeqSJPWo7zCoqm8z//l+gA3z9C/gwgX2dQVwRb+1SJIG4zuQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYhmFQZLTk9ybZEeSLaOuR5JWklWjLgAgyUHAp4G/BGaA25LcUFX3jLay8bFuy43ztl983B7OX2DbMDx46RsWbd+ShmdZhAFwIrCjqu4HSHI1sBEYqzBY6B/kcTbK73mlBdFizPWB/rEwqrleytfXYv/hdKAWa65TVYuy456KSN4MnF5Vf9PW3wK8uqrevk+/zcDmtvoy4N4+v+QRwM/6HDtunIu5nI+5nI9Z4zAXL6qq58+3YbkcGWSetj9JqaraCmwd+Islt1fV5KD7GQfOxVzOx1zOx6xxn4vlcgF5Bljbtb4GeGREtUjSirNcwuA2YH2So5I8DTgHuGHENUnSirEsThNV1Z4kbwduAg4CrqiquxfxSw58qmmMOBdzOR9zOR+zxnoulsUFZEnSaC2X00SSpBEyDCRJKysMfOTFrCRrk3wryfYkdye5aNQ1jVqSg5LcleSro65l1JIcmuTaJD9sr5HXjLqmUUry7vZ78oMkX0ryjFHXNGwrJgy6HnlxBnAMcG6SY0Zb1UjtAS6uqpcDJwEXrvD5ALgI2D7qIpaJTwBfr6qjgVeyguclyWrgncBkVR1L5yaXc0Zb1fCtmDCg65EXVfU7YO8jL1akqtpZVXe25V/Q+WVfPdqqRifJGuANwGWjrmXUkjwHeB1wOUBV/a6qHh9tVSO3CnhmklXAwYzh+6BWUhisBh7uWp9hBf/j1y3JOuB44NbRVjJSHwfeA/zfqAtZBl4M/BT4XDttdlmSQ0Zd1KhU1Y+AjwAPATuBJ6rqG6OtavhWUhgc0CMvVpokzwK+Aryrqn4+6npGIckbgUer6o5R17JMrAJOAD5bVccDvwRW7DW2JIfROYtwFPBC4JAkfz3aqoZvJYWBj7zYR5Kn0gmCL1TVdaOuZ4ROBt6U5EE6pw9PSfKvoy1ppGaAmarae6R4LZ1wWKleDzxQVT+tqt8D1wGvHXFNQ7eSwsBHXnRJEjrnhLdX1UdHXc8oVdV7q2pNVa2j87r4ZlWN3V9+B6qqfgw8nORlrWkDY/Y4+R49BJyU5OD2e7OBMbygviweR7EURvDIi+XuZOAtwPeTfLe1va+qvjbCmrR8vAP4QvvD6X7gbSOuZ2Sq6tYk1wJ30rkL7y7G8NEUPo5CkrSiThNJkhZgGEiSDANJkmEgScIwkCRhGEg9S/JXSSrJ0W19XZJft0c3bE/ynSSbuvpPJPlqkv9Kck8Sb9/VsrNi3mcgDdG5wLfpvEHtH1vb/7RHN5DkxcB1SZ5SVZ8D3g9sq6pPtO1/sfQlS0/OIwOpB+1ZTicDF7DAY4yr6n7g7+g89hjgSDqPeNi7/XuLXKbUM8NA6s1ZdJ7z/9/AriQLPbPnTuDotvxp4PL2nwn9Q5IXLkWhUi8MA6k359J5mB3t87kL9PvjU3Kr6iY6j4X+ZzoBcVeS5y9mkVKvvGYgHaAkzwNOAY5NUnSecVXAZ+bpfjxdDzOrql3AF4Evtv9W83V0nhgrLQseGUgH7s3AVVX1oqpaV1VrgQfoPA79j9p/FvQR4FNt/ZQkB7flZwMvofMkTGnZ8MhAOnDnApfu0/YV4H3AS5LcBTwD+AXwqXYnEcCrgH9KsofOH2CXVdVtS1SzdEB8aqkkydNEkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJOD/ATQ+c6tSf8kzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Dataset/Ads_CTR_Optimisation.csv')\n",
    "\n",
    "# is it better than UCB?\n",
    "import math\n",
    "import random\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "N_0 = [0] * d\n",
    "N_1 = [0] * d\n",
    "total_reward = 0\n",
    "\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_random = 0\n",
    "    for i in range(0, d):\n",
    "        theta = random.betavariate(N_0[i]+1, N_1[i]+1)\n",
    "        if (theta > max_random):\n",
    "            max_random = theta\n",
    "            ad = i\n",
    "    ads_selected.append(ad)\n",
    "    reward = dataset.values[n, ad]\n",
    "    if reward == 0:\n",
    "        N_0[ad] = N_0[ad] + 1\n",
    "    if reward == 1:\n",
    "        N_1[ad] = N_1[ad] + 1\n",
    "    total_reward = total_reward + reward\n",
    "\n",
    "plt.hist(ads_selected)\n",
    "plt.xlabel('ADS')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best one is the TS because with 500 obsevations, it's able to find the best ad. In more situations it's better than UCB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> DIFFERENCES BETWEEN TECHNIQUES </h3></center>\n",
    "\n",
    "- UCB is a deterministic algorithm, TS is a probabilistic one because the sampling is part of the methodology.\n",
    "- UCB requires update at every round, TS can accomodate delayed feedback (indeed it's possible to collect several result and then modifies the distribution).\n",
    "- TS has a better empirical evidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
