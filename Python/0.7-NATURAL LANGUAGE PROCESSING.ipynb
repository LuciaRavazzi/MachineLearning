{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> NATURAL LANGUAGE PROCESSING </h1></center>\n",
    "\n",
    "Natural Language Processing (or NLP) is applying *Machine Learning models to text and language*. \n",
    "Teaching machines to understand what is said in spoken and written word is the focus of Natural Language Processing. Whenever you dictate something into your iPhone / Android device that is then converted to text, thatâ€™s an NLP algorithm in action.\n",
    "\n",
    "You can also use NLP on a text review to predict if the review is a good one or a bad one. \n",
    "You can use NLP on an article to predict some categories of the articles you are trying to segment. \n",
    "You can use NLP on a book to predict the genre of the book. And it can go further, you can use NLP to build a machine translator or a speech recognition system, and in that last example you use classification algorithms to classify language. Speaking of classification algorithms, most of NLP algorithms are classification models, and they include Logistic Regression, Naive Bayes, CART which is a model based on decision trees, Maximum Entropy again related to Decision Trees, Hidden Markov Models which are models based on Markov processes.\n",
    "\n",
    "A very well-known model in NLP is the Bag of Words model. It is a model used to preprocess the texts to classify before fitting the classification algorithms on the observations containing the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of NLP:\n",
    "- Natural Language Processing.\n",
    "- Deep Learning: algorithms which are related to neural network. \n",
    "- The intersection of the two is the DNLP.\n",
    "- Seq2Seq (sequence to sequence) is a subsection of DNLP and it's the most powerful tool for NLP. \n",
    "\n",
    "Theme: Classical vs. Deep learning models. Some examples:\n",
    "- If/else is the rules for the chatbot. It refers to the mechanism which identifies the correct answer within the huge amount of questions. (NLP)\n",
    "- Audio frequency components analysis (Speech recognition) (NLP). It also a mathematical computation without the using of neural network. \n",
    "- Bag of words model classification (NLP). It can be used in order to classify a positive or negative sentence.\n",
    "- CNN for text recognition (Classification) (DNLP).\n",
    "- Seq2Seq.\n",
    "\n",
    "We focus on the *bag-of-words model*. Gmail gives a possible answers to an email. We want to create a model that will give us an yes/no response to our friend. We select the bag of words as the set of words most used in the UK with a vector of zero. Then, put one or more if the word is present in the email. We analize all of the emails which define the training data: the X variable is the email while the Y variable is Yes/No, it's a classification. So, actually we are defining a table in which each entries is the filled vector of the bag of word, while the variable to be predicted is binary: it's a well-known classification model! Vectors are sparse. This is a NLP classification technique. We can use also the neural network which is fed by the vectors in order to define the parameters (DNLP technique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lucia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:  0.73 \n",
      " Confusion matrix: \n",
      " [[55 42]\n",
      " [12 91]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def after_class(classifier, X_test, Y_test):\n",
    "    # CONFUSION MATRIX: C00 is the true negative. \n",
    "    # Column is the result of the predictor.\n",
    "    CM = confusion_matrix(Y_test, classifier.predict(X_test))\n",
    "    ACC = accuracy_score(Y_test, classifier.predict(X_test))\n",
    "    print('\\n Accuracy: ', ACC, '\\n', 'Confusion matrix: \\n', CM)\n",
    "\n",
    "# We perform the sentimental analysis. Chatbot and translated are defined in advanced NLP.\n",
    "\n",
    "# the dataset collects the reviews of a restaurant and the binary variable.\n",
    "dataset = pd.read_csv('Dataset/Restaurant_Reviews.tsv', \n",
    "                      sep = '\\t',\n",
    "                     quoting = 3 # ignore quotes.\n",
    "                     )\n",
    "\n",
    "# CLEAN THE TEST.\n",
    "import re \n",
    "import nltk # download the stop words (articles, prepositions etc.)\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer # stemming: It also reduces the final dimension of the bag of words.\n",
    "# also the puntaction will be removed.\n",
    "\n",
    "corpus = [] # it contains all reviews after the ceaning process. \n",
    "\n",
    "for i in range (0, dataset.shape[0]):\n",
    "    # replace anything in a text with anything I want: \n",
    "    # I substitute punctuation and digit with a white space.\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i]) \n",
    "    # lower case.\n",
    "    review = review.lower()\n",
    "    # stemming process.\n",
    "    review = review.split() # primitive bag of words.\n",
    "    ps = PorterStemmer()\n",
    "    # if the word isn't an english stopword, then it's saved into the list.\n",
    "    # tokenization.\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not') # don't include not in the stopwords.\n",
    "    review = [ps.stem(word) for word in review if not word in set()]\n",
    "    # join the selected words. \n",
    "    review = ' '.join(review) # join the word with a space for eah review. \n",
    "    corpus.append(review) \n",
    "\n",
    "# CREATE THE BAG OF WORDS.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# define the most frequent word in the reviews.\n",
    "# total number of words is 1655 but we want to delete some unuseful words. \n",
    "cv = CountVectorizer(max_features = 1500)  # it's possible to specify the dimension of the bag of words.\n",
    "\n",
    "# dependent and independent variables.\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "Y = dataset.iloc[:,-1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, # independent variables.\n",
    "                                                    Y, # dependent variables.\n",
    "                                                    test_size = 0.2, # size of test set.\n",
    "                                                    random_state = 0) # fix the seed for both of data set.\n",
    "\n",
    "# Naive Bayes classification.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# the function for the probability is a normal distribution. \n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, Y_train)\n",
    "\n",
    "# confusion matrix.\n",
    "after_class(NB, X_test, Y_test)\n",
    "\n",
    "# it's possible to improve this result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
